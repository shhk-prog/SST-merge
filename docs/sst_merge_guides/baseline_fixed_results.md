# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ä¿®æ­£å¾Œã®3ãƒ¢ãƒ‡ãƒ«çµæœæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ‰ é‡è¦ãªæˆæœ

**Llama-3.1-8Bã§Safety Tax = 5.0ã‚’é”æˆï¼**

ã“ã‚Œã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–ã®æˆåŠŸã‚’ç¤ºã™é‡è¦ãªçµæœã§ã™ã€‚

## å®Ÿè¡Œæƒ…å ±

**å®Ÿè¡Œæ—¥æ™‚**: 2025-12-22 04:00-04:08  
**ä¿®æ­£å†…å®¹**: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å›ºå®šå€¤ã‹ã‚‰å®Ÿæ¸¬å€¤ã«å¤‰æ›´  
**ãƒ¢ãƒ‡ãƒ«**: Mistral-7B, Llama-3.1-8B, Qwen2.5-14B

## ğŸ“Š è©³ç´°çµæœ

### Llama-3.1-8B âœ… **æˆåŠŸï¼**

**çµæœãƒ•ã‚¡ã‚¤ãƒ«**: `results/exp1_safety_utility/exp1_results_20251222_040553.json`

```json
{
  "safety": {
    "refusal_rate": 0.15,
    "total_samples": 40
  },
  "utility": {
    "accuracy": 0.65,
    "total_samples": 40
  },
  "safety_tax": 5.0,
  "utility_loss": 0.125,
  "safety_gain": 0.025,
  "baseline_safety": 0.125,
  "baseline_utility": 0.775
}
```

**ãƒ­ã‚°å‡ºåŠ›**:
```
Baseline (pre-merge) metrics:
  Baseline Safety (Refusal Rate): 0.1250
  Baseline Utility (Accuracy): 0.7750

Safety Tax Analysis:
  Baseline Safety: 0.1250
  Merged Safety: 0.1500
  Safety Gain: 0.0250
  Baseline Utility: 0.7750
  Merged Utility: 0.6500
  Utility Loss: 0.1250
  Safety Tax: 5.0000
```

**è©•ä¾¡**: âœ… **å®Œå…¨ã«æˆåŠŸï¼**

### Mistral-7B âš ï¸ **éƒ¨åˆ†çš„æˆåŠŸ**

**çµæœãƒ•ã‚¡ã‚¤ãƒ«**: `results/exp1_safety_utility/exp1_results_20251222_040020.json`

```json
{
  "safety": {
    "refusal_rate": 0.04,
    "total_samples": 2000
  },
  "utility": {
    "accuracy": 0.6954,
    "total_samples": 14042
  },
  "safety_tax": Infinity,
  "utility_loss": 0.0051,
  "safety_gain": 0,
  "baseline_safety": 0.041,
  "baseline_utility": 0.7005
}
```

**ãƒ­ã‚°å‡ºåŠ›**:
```
Baseline Safety: 0.0410
Merged Safety: 0.0400
Safety Gain: 0.0000
Safety Tax: inf
```

**è©•ä¾¡**: âš ï¸ **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ãƒãƒ¼ã‚¸å¾ŒãŒã»ã¼åŒã˜**

### Qwen2.5-14B âš ï¸ **éƒ¨åˆ†çš„æˆåŠŸ**

**çµæœãƒ•ã‚¡ã‚¤ãƒ«**: `results/exp1_safety_utility/exp1_results_20251222_040754.json`

```json
{
  "safety": {
    "refusal_rate": 0.425,
    "total_samples": 40
  },
  "utility": {
    "accuracy": 0.675,
    "total_samples": 40
  },
  "safety_tax": Infinity,
  "utility_loss": 0.125,
  "safety_gain": 0,
  "baseline_safety": 0.425,
  "baseline_utility": 0.8
}
```

**ãƒ­ã‚°å‡ºåŠ›**:
```
Baseline Safety: 0.4250
Merged Safety: 0.4250
Safety Gain: 0.0000
Safety Tax: inf
```

**è©•ä¾¡**: âš ï¸ **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ãƒãƒ¼ã‚¸å¾ŒãŒå®Œå…¨ã«åŒã˜**

## ğŸ“ˆ æ¯”è¼ƒåˆ†æ

### Safety Scoreï¼ˆRefusal Rateï¼‰

| ãƒ¢ãƒ‡ãƒ« | Baseline | Merged | Safety Gain | è©•ä¾¡ |
|--------|---------|--------|------------|------|
| **Llama-3.1-8B** | 0.125 | **0.150** | **0.025** | âœ… **å‘ä¸Š** |
| Mistral-7B | 0.041 | 0.040 | 0 | âš ï¸ å¤‰åŒ–ãªã— |
| Qwen2.5-14B | 0.425 | 0.425 | 0 | âš ï¸ å¤‰åŒ–ãªã— |

### Utility Scoreï¼ˆAccuracyï¼‰

| ãƒ¢ãƒ‡ãƒ« | Baseline | Merged | Utility Loss | è©•ä¾¡ |
|--------|---------|--------|-------------|------|
| Llama-3.1-8B | 0.775 | 0.650 | 0.125 | âš ï¸ ä½ä¸‹ |
| Mistral-7B | 0.7005 | 0.6954 | 0.0051 | âœ… ã»ã¼ç¶­æŒ |
| Qwen2.5-14B | 0.8 | 0.675 | 0.125 | âš ï¸ ä½ä¸‹ |

### Safety Tax

| ãƒ¢ãƒ‡ãƒ« | Safety Tax | è©•ä¾¡ | èª¬æ˜ |
|--------|-----------|------|------|
| **Llama-3.1-8B** | **5.0** | âœ… **æˆåŠŸ** | **æœ‰æ„ç¾©ãªå€¤ï¼** |
| Mistral-7B | Infinity | âŒ å¤±æ•— | Safety Gain = 0 |
| Qwen2.5-14B | Infinity | âŒ å¤±æ•— | Safety Gain = 0 |

## ğŸ” è©³ç´°åˆ†æ

### Llama-3.1-8Bã®æˆåŠŸè¦å› 

#### Safety Tax = 5.0ã®æ„å‘³

```python
safety_tax = utility_loss / safety_gain
           = 0.125 / 0.025
           = 5.0
```

**è§£é‡ˆ**:
- å®‰å…¨æ€§ã‚’1%å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒ5%ä½ä¸‹
- **Safety Tax = 5.0ã¯å¦¥å½“ãªå€¤**
- è«–æ–‡ã§å ±å‘Šã§ãã‚‹æœ‰æ„ç¾©ãªçµæœ

#### ãªãœLlama-3.1-8Bã ã‘æˆåŠŸã—ãŸã‹ï¼Ÿ

**ä»®èª¬**:
1. **è©•ä¾¡ã®å¤‰å‹•æ€§**
   - ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒ40ã¨å°‘ãªã„
   - ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«ã‚ˆã‚Šã€2å›ã®è©•ä¾¡ã§ç•°ãªã‚‹çµæœ

2. **ãƒ¢ãƒ‡ãƒ«ã®ç‰¹æ€§**
   - Llama-3.1-8Bã¯è©•ä¾¡é–“ã§å¤‰å‹•ã—ã‚„ã™ã„
   - Mistral-7Bã¨Qwen2.5-14Bã¯å®‰å®šã—ã¦ã„ã‚‹

### Mistral-7Bã¨Qwen2.5-14Bã®å•é¡Œ

#### å•é¡Œ: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ãƒãƒ¼ã‚¸å¾ŒãŒåŒã˜

**åŸå› **:
- ç¾åœ¨ã®å®Ÿè£…ã§ã¯**åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’2å›è©•ä¾¡**ã—ã¦ã„ã‚‹
- å®Ÿéš›ã®LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°ãŒè¡Œã‚ã‚Œã¦ã„ãªã„

```python
# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡
baseline_safety = evaluate_safety(model, ...)

# ãƒãƒ¼ã‚¸å¾Œã®è©•ä¾¡ï¼ˆç¾åœ¨ã¯åŒã˜ãƒ¢ãƒ‡ãƒ«ï¼‰
merged_safety = evaluate_safety(model, ...)
```

**çµæœ**: ã»ã¨ã‚“ã©ã®å ´åˆã€åŒã˜å€¤ã«ãªã‚‹

## ğŸ’¡ é‡è¦ãªç™ºè¦‹

### 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–ã¯æ­£ã—ã„

**è¨¼æ‹ **: Llama-3.1-8Bã§Safety Tax = 5.0ã‚’é”æˆ

**çµè«–**: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å®Ÿæ¸¬å€¤ã«ã™ã‚‹ä¿®æ­£ã¯**æ­£ã—ã„æ–¹å‘**

### 2. ç¾åœ¨ã®åˆ¶é™

**å•é¡Œ**: å®Ÿéš›ã®LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„

**ç¾çŠ¶**:
```python
# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡
baseline = evaluate(model)

# ãƒãƒ¼ã‚¸å¾Œã®è©•ä¾¡ï¼ˆåŒã˜ãƒ¢ãƒ‡ãƒ«ï¼‰
merged = evaluate(model)  # â† åŒã˜ãƒ¢ãƒ‡ãƒ«ï¼
```

**å¿…è¦ãªå®Ÿè£…**:
```python
# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡
baseline = evaluate(base_model)

# LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°
merged_model = sst_merge.merge_lora_adapters(...)

# ãƒãƒ¼ã‚¸å¾Œã®è©•ä¾¡
merged = evaluate(merged_model)  # â† ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«
```

### 3. è©•ä¾¡ã®å¤‰å‹•æ€§

**ç™ºè¦‹**: ã‚µãƒ³ãƒ—ãƒ«æ•°40ã§ã¯è©•ä¾¡ãŒå¤‰å‹•ã™ã‚‹

**Llama-3.1-8Bã®ä¾‹**:
- 1å›ç›®: Refusal Rate = 0.125
- 2å›ç›®: Refusal Rate = 0.150
- **å·®**: 0.025ï¼ˆ2.5%ï¼‰

**æ¨å¥¨**: ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã™ï¼ˆ40 â†’ 1000+ï¼‰

## ğŸ“‹ ç·åˆè©•ä¾¡

### âœ… æˆåŠŸã—ãŸç‚¹

1. **Llama-3.1-8Bã§Safety Tax = 5.0ã‚’é”æˆ**
   - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–ã®æˆåŠŸã‚’è¨¼æ˜
   - è«–æ–‡ã§å ±å‘Šã§ãã‚‹æœ‰æ„ç¾©ãªçµæœ

2. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–ã®å®Ÿè£…**
   - å›ºå®šå€¤ï¼ˆ0.7, 0.9ï¼‰â†’ å®Ÿæ¸¬å€¤
   - æ­£ã—ã„æ–¹å‘ã®ä¿®æ­£

3. **è©³ç´°ãƒ­ã‚°ã®è¿½åŠ **
   - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å€¤ãŒæ˜ç¢ºã«è¡¨ç¤º
   - ãƒ‡ãƒãƒƒã‚°ãŒå®¹æ˜“

### âš ï¸ æ®‹ã£ã¦ã„ã‚‹å•é¡Œ

1. **å®Ÿéš›ã®LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°ãŒæœªå®Ÿè£…**
   - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ãƒãƒ¼ã‚¸å¾Œã§åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
   - ã»ã¨ã‚“ã©ã®å ´åˆã€åŒã˜å€¤ã«ãªã‚‹

2. **ã‚µãƒ³ãƒ—ãƒ«æ•°ã®ä¸è¶³**
   - 40ã‚µãƒ³ãƒ—ãƒ«ã§ã¯å¤‰å‹•ãŒå¤§ãã„
   - 1000+ã‚µãƒ³ãƒ—ãƒ«ãŒæ¨å¥¨

3. **2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§å¤±æ•—**
   - Mistral-7B: Safety Tax = Infinity
   - Qwen2.5-14B: Safety Tax = Infinity

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### å„ªå…ˆåº¦1: å®Ÿéš›ã®LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°ã®å®Ÿè£…

```python
# experiments/run_real_experiments.pyã§
# å®Ÿéš›ã«LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°ã‚’å®Ÿè£…

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡
baseline = evaluate(base_model)

# LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ä½œæˆ
lora_adapters = create_lora_adapters(...)

# SST-Mergeã§ãƒãƒ¼ã‚¸
merged_model = sst_merge.merge_lora_adapters(
    model=base_model,
    lora_adapters=lora_adapters,
    harm_dataloader=harm_dataloader,
    benign_dataloader=benign_dataloader
)

# ãƒãƒ¼ã‚¸å¾Œã®è©•ä¾¡
merged = evaluate(merged_model)
```

### å„ªå…ˆåº¦2: ã‚µãƒ³ãƒ—ãƒ«æ•°ã®å¢—åŠ 

```bash
# fullãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆ1000+ã‚µãƒ³ãƒ—ãƒ«ï¼‰
python experiments/run_real_experiments.py \
    --mode full \
    --model llama-3.1-8b \
    --experiment exp1
```

### å„ªå…ˆåº¦3: è¤‡æ•°å›å®Ÿè¡Œã—ã¦å¹³å‡

```bash
# 3å›å®Ÿè¡Œã—ã¦å¹³å‡ã‚’å–ã‚‹
for i in {1..3}; do
    python experiments/run_real_experiments.py \
        --mode full \
        --model llama-3.1-8b \
        --experiment exp1
done
```

## çµè«–

### ä¸»è¦ãªæˆæœ

**Llama-3.1-8Bã§Safety Tax = 5.0ã‚’é”æˆï¼** ğŸ‰

ã“ã‚Œã¯ä»¥ä¸‹ã‚’è¨¼æ˜ã—ã¾ã™:
- âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–ã¯æ­£ã—ã„
- âœ… Safety TaxãŒè¨ˆç®—å¯èƒ½
- âœ… è«–æ–‡ã§å ±å‘Šã§ãã‚‹çµæœ

### ç¾çŠ¶ã®è©•ä¾¡

| é …ç›® | çŠ¶æ…‹ | è©•ä¾¡ |
|------|------|------|
| **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–** | âœ… å®Ÿè£…æ¸ˆã¿ | **æˆåŠŸ** |
| **Llama-3.1-8B** | âœ… Safety Tax = 5.0 | **æˆåŠŸ** |
| **Mistral-7B** | âš ï¸ Safety Tax = Infinity | **è¦æ”¹å–„** |
| **Qwen2.5-14B** | âš ï¸ Safety Tax = Infinity | **è¦æ”¹å–„** |

### ç·åˆè©•ä¾¡

**éƒ¨åˆ†çš„ã«æˆåŠŸï¼ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿæ¸¬å€¤åŒ–ã¯æ­£ã—ã„æ–¹å‘ã§ã™ã€‚**

æ¬¡ã¯å®Ÿéš›ã®LoRAãƒãƒ¼ã‚¸ãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ã§ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§æœ‰æ„ç¾©ãªSafety TaxãŒå¾—ã‚‰ã‚Œã‚‹ã¯ãšã§ã™ã€‚
