/mnt/iag-02/home/hiromi/src/SST_merge/sst/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-12-24 00:54:04,029 - __main__ - INFO - 
================================================================================
2025-12-24 00:54:04,029 - __main__ - INFO - A7 (Security) MODEL CREATION
2025-12-24 00:54:04,030 - __main__ - INFO - ================================================================================
2025-12-24 00:54:04,030 - __main__ - INFO - 
Loading training dataset...
2025-12-24 00:54:04,232 - src.utils.instruction_loaders - INFO - Loading Security dataset from data/response_dataframe.csv...
2025-12-24 00:54:04,242 - src.utils.instruction_loaders - INFO - Loaded 1400 samples from Security dataset
2025-12-24 00:54:04,243 - src.utils.instruction_loaders - INFO - Created Security DataLoader: 1400 samples, batch_size=32
2025-12-24 00:54:04,244 - __main__ - INFO - ✓ Dataset loaded
2025-12-24 00:54:04,244 - __main__ - INFO - 
Loading model: mistral-7b-v0.2...
2025-12-24 00:54:04,244 - src.utils.model_loader - INFO - ModelLoader initialized: model=mistralai/Mistral-7B-Instruct-v0.2, device_map=auto, dtype=torch.bfloat16
2025-12-24 00:54:04,244 - src.utils.model_loader - INFO - Loading model: mistralai/Mistral-7B-Instruct-v0.2
2025-12-24 00:54:05,551 - src.utils.model_loader - INFO - Using Flash Attention 2 for faster inference
`torch_dtype` is deprecated! Use `dtype` instead!
2025-12-24 00:54:06,134 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.20it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.16it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]
2025-12-24 00:54:09,094 - src.utils.model_loader - INFO - ✓ Model loaded successfully: mistralai/Mistral-7B-Instruct-v0.2
2025-12-24 00:54:09,095 - src.utils.model_loader - INFO -   Total parameters: 7.24B
2025-12-24 00:54:09,095 - src.utils.model_loader - INFO -   Device map: {'': 0}
2025-12-24 00:54:09,095 - __main__ - INFO - ✓ Model loaded
2025-12-24 00:54:09,095 - __main__ - INFO - 
Fine-tuning on Security data...
2025-12-24 00:54:09,095 - src.lora_trainer - INFO - LoRATrainer initialized on device: cuda
2025-12-24 00:54:09,095 - src.lora_trainer - INFO - 
Training LoRA adapter for benign task...
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   Epochs: 3
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   Learning rate: 0.0002
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   LoRA rank: 32
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   LoRA alpha: 64
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   LoRA dropout: 0.0
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   Weight decay: 0.01
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   Warmup ratio: 0.1
2025-12-24 00:54:09,095 - src.lora_trainer - INFO -   Gradient accumulation steps: 4
2025-12-24 00:54:11,644 - src.lora_trainer - INFO -   Gradient checkpointing enabled
2025-12-24 00:54:11,657 - src.lora_trainer - INFO -   Total training steps: 132
2025-12-24 00:54:11,657 - src.lora_trainer - INFO -   Warmup steps: 13
/mnt/iag-02/home/hiromi/src/SST_merge/src/lora_trainer.py:206: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
2025-12-24 00:54:11,657 - src.lora_trainer - INFO -   Mixed precision training enabled
Epoch 1/3:   0%|          | 0/44 [00:00<?, ?it/s]/mnt/iag-02/home/hiromi/src/SST_merge/src/lora_trainer.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
Casting fp32 inputs back to torch.float16 for flash-attn compatibility.
Epoch 1/3:   0%|          | 0/44 [00:02<?, ?it/s, loss=1.3664]Epoch 1/3:   2%|▏         | 1/44 [00:02<02:08,  2.99s/it, loss=1.3664]Epoch 1/3:   2%|▏         | 1/44 [00:05<02:08,  2.99s/it, loss=1.3376]Epoch 1/3:   5%|▍         | 2/44 [00:05<01:54,  2.73s/it, loss=1.3376]Epoch 1/3:   5%|▍         | 2/44 [00:08<01:54,  2.73s/it, loss=1.3554]Epoch 1/3:   7%|▋         | 3/44 [00:08<01:47,  2.63s/it, loss=1.3554]Epoch 1/3:   7%|▋         | 3/44 [00:11<01:47,  2.63s/it, loss=1.3798]Epoch 1/3:   9%|▉         | 4/44 [00:11<01:53,  2.84s/it, loss=1.3798]Epoch 1/3:   9%|▉         | 4/44 [00:12<01:53,  2.84s/it, loss=1.1958]Epoch 1/3:  11%|█▏        | 5/44 [00:12<01:27,  2.24s/it, loss=1.1958]Epoch 1/3:  11%|█▏        | 5/44 [00:14<01:27,  2.24s/it, loss=1.3531]Epoch 1/3:  14%|█▎        | 6/44 [00:14<01:29,  2.36s/it, loss=1.3531]Epoch 1/3:  14%|█▎        | 6/44 [00:16<01:29,  2.36s/it, loss=1.1862]Epoch 1/3:  16%|█▌        | 7/44 [00:16<01:11,  1.93s/it, loss=1.1862]Epoch 1/3:  16%|█▌        | 7/44 [00:18<01:11,  1.93s/it, loss=1.3671]Epoch 1/3:  18%|█▊        | 8/44 [00:18<01:17,  2.14s/it, loss=1.3671]Epoch 1/3:  18%|█▊        | 8/44 [00:21<01:17,  2.14s/it, loss=0.6778]Epoch 1/3:  20%|██        | 9/44 [00:21<01:19,  2.28s/it, loss=0.6778]Epoch 1/3:  20%|██        | 9/44 [00:24<01:19,  2.28s/it, loss=0.6804]Epoch 1/3:  23%|██▎       | 10/44 [00:24<01:23,  2.46s/it, loss=0.6804]Epoch 1/3:  23%|██▎       | 10/44 [00:26<01:23,  2.46s/it, loss=0.6724]Epoch 1/3:  25%|██▌       | 11/44 [00:26<01:24,  2.57s/it, loss=0.6724]Epoch 1/3:  25%|██▌       | 11/44 [00:29<01:24,  2.57s/it, loss=0.6797]Epoch 1/3:  27%|██▋       | 12/44 [00:29<01:24,  2.65s/it, loss=0.6797]Epoch 1/3:  27%|██▋       | 12/44 [00:32<01:24,  2.65s/it, loss=0.1599]Epoch 1/3:  30%|██▉       | 13/44 [00:32<01:23,  2.70s/it, loss=0.1599]Epoch 1/3:  30%|██▉       | 13/44 [00:35<01:23,  2.70s/it, loss=0.1627]Epoch 1/3:  32%|███▏      | 14/44 [00:35<01:21,  2.73s/it, loss=0.1627]Epoch 1/3:  32%|███▏      | 14/44 [00:38<01:21,  2.73s/it, loss=0.1696]Epoch 1/3:  34%|███▍      | 15/44 [00:38<01:19,  2.75s/it, loss=0.1696]Epoch 1/3:  34%|███▍      | 15/44 [00:40<01:19,  2.75s/it, loss=0.1665]Epoch 1/3:  36%|███▋      | 16/44 [00:40<01:17,  2.77s/it, loss=0.1665]Epoch 1/3:  36%|███▋      | 16/44 [00:43<01:17,  2.77s/it, loss=0.1468]Epoch 1/3:  39%|███▊      | 17/44 [00:43<01:15,  2.80s/it, loss=0.1468]Epoch 1/3:  39%|███▊      | 17/44 [00:46<01:15,  2.80s/it, loss=0.1338]Epoch 1/3:  41%|████      | 18/44 [00:46<01:12,  2.80s/it, loss=0.1338]Epoch 1/3:  41%|████      | 18/44 [00:49<01:12,  2.80s/it, loss=0.1563]Epoch 1/3:  43%|████▎     | 19/44 [00:49<01:10,  2.80s/it, loss=0.1563]Epoch 1/3:  43%|████▎     | 19/44 [00:52<01:10,  2.80s/it, loss=0.1475]Epoch 1/3:  45%|████▌     | 20/44 [00:52<01:07,  2.82s/it, loss=0.1475]Epoch 1/3:  45%|████▌     | 20/44 [00:55<01:07,  2.82s/it, loss=0.1223]Epoch 1/3:  48%|████▊     | 21/44 [00:55<01:05,  2.83s/it, loss=0.1223]Epoch 1/3:  48%|████▊     | 21/44 [00:57<01:05,  2.83s/it, loss=0.1340]Epoch 1/3:  50%|█████     | 22/44 [00:57<01:01,  2.82s/it, loss=0.1340]Epoch 1/3:  50%|█████     | 22/44 [01:00<01:01,  2.82s/it, loss=0.1459]Epoch 1/3:  52%|█████▏    | 23/44 [01:00<00:59,  2.83s/it, loss=0.1459]Epoch 1/3:  52%|█████▏    | 23/44 [01:03<00:59,  2.83s/it, loss=0.1102]Epoch 1/3:  55%|█████▍    | 24/44 [01:03<00:56,  2.82s/it, loss=0.1102]Epoch 1/3:  55%|█████▍    | 24/44 [01:06<00:56,  2.82s/it, loss=0.1138]Epoch 1/3:  57%|█████▋    | 25/44 [01:06<00:53,  2.82s/it, loss=0.1138]Epoch 1/3:  57%|█████▋    | 25/44 [01:09<00:53,  2.82s/it, loss=0.1256]Epoch 1/3:  59%|█████▉    | 26/44 [01:09<00:51,  2.84s/it, loss=0.1256]Epoch 1/3:  59%|█████▉    | 26/44 [01:12<00:51,  2.84s/it, loss=0.1286]Epoch 1/3:  61%|██████▏   | 27/44 [01:12<00:48,  2.85s/it, loss=0.1286]Epoch 1/3:  61%|██████▏   | 27/44 [01:15<00:48,  2.85s/it, loss=0.1159]Epoch 1/3:  64%|██████▎   | 28/44 [01:15<00:45,  2.85s/it, loss=0.1159]Epoch 1/3:  64%|██████▎   | 28/44 [01:17<00:45,  2.85s/it, loss=0.1219]Epoch 1/3:  66%|██████▌   | 29/44 [01:17<00:42,  2.84s/it, loss=0.1219]Epoch 1/3:  66%|██████▌   | 29/44 [01:20<00:42,  2.84s/it, loss=0.1183]Epoch 1/3:  68%|██████▊   | 30/44 [01:20<00:39,  2.83s/it, loss=0.1183]Epoch 1/3:  68%|██████▊   | 30/44 [01:23<00:39,  2.83s/it, loss=0.1154]Epoch 1/3:  70%|███████   | 31/44 [01:23<00:36,  2.82s/it, loss=0.1154]Epoch 1/3:  70%|███████   | 31/44 [01:26<00:36,  2.82s/it, loss=0.1221]Epoch 1/3:  73%|███████▎  | 32/44 [01:26<00:33,  2.83s/it, loss=0.1221]Epoch 1/3:  73%|███████▎  | 32/44 [01:29<00:33,  2.83s/it, loss=0.1125]Epoch 1/3:  75%|███████▌  | 33/44 [01:29<00:31,  2.84s/it, loss=0.1125]Epoch 1/3:  75%|███████▌  | 33/44 [01:31<00:31,  2.84s/it, loss=0.1193]Epoch 1/3:  77%|███████▋  | 34/44 [01:31<00:28,  2.83s/it, loss=0.1193]Epoch 1/3:  77%|███████▋  | 34/44 [01:34<00:28,  2.83s/it, loss=0.1084]Epoch 1/3:  80%|███████▉  | 35/44 [01:34<00:25,  2.84s/it, loss=0.1084]Epoch 1/3:  80%|███████▉  | 35/44 [01:37<00:25,  2.84s/it, loss=0.1093]Epoch 1/3:  82%|████████▏ | 36/44 [01:37<00:22,  2.76s/it, loss=0.1093]Epoch 1/3:  82%|████████▏ | 36/44 [01:40<00:22,  2.76s/it, loss=0.1130]Epoch 1/3:  84%|████████▍ | 37/44 [01:40<00:19,  2.80s/it, loss=0.1130]Epoch 1/3:  84%|████████▍ | 37/44 [01:43<00:19,  2.80s/it, loss=0.0899]Epoch 1/3:  86%|████████▋ | 38/44 [01:43<00:16,  2.80s/it, loss=0.0899]Epoch 1/3:  86%|████████▋ | 38/44 [01:45<00:16,  2.80s/it, loss=0.1017]Epoch 1/3:  89%|████████▊ | 39/44 [01:45<00:13,  2.79s/it, loss=0.1017]Epoch 1/3:  89%|████████▊ | 39/44 [01:48<00:13,  2.79s/it, loss=0.1215]Epoch 1/3:  91%|█████████ | 40/44 [01:48<00:11,  2.80s/it, loss=0.1215]Epoch 1/3:  91%|█████████ | 40/44 [01:50<00:11,  2.80s/it, loss=0.1697]Epoch 1/3:  93%|█████████▎| 41/44 [01:50<00:07,  2.50s/it, loss=0.1697]Epoch 1/3:  93%|█████████▎| 41/44 [01:53<00:07,  2.50s/it, loss=0.0932]Epoch 1/3:  95%|█████████▌| 42/44 [01:53<00:05,  2.58s/it, loss=0.0932]Epoch 1/3:  95%|█████████▌| 42/44 [01:56<00:05,  2.58s/it, loss=0.0944]Epoch 1/3:  98%|█████████▊| 43/44 [01:56<00:02,  2.67s/it, loss=0.0944]Epoch 1/3:  98%|█████████▊| 43/44 [01:58<00:02,  2.67s/it, loss=0.1083]Epoch 1/3: 100%|██████████| 44/44 [01:58<00:00,  2.51s/it, loss=0.1083]Epoch 1/3: 100%|██████████| 44/44 [01:58<00:00,  2.69s/it, loss=0.1083]
2025-12-24 00:56:09,906 - src.lora_trainer - INFO - 
============================================================
2025-12-24 00:56:09,906 - src.lora_trainer - INFO - Epoch 1/3 Summary
2025-12-24 00:56:09,906 - src.lora_trainer - INFO - ============================================================
2025-12-24 00:56:09,906 - src.lora_trainer - INFO -   Train Loss:    0.3934
2025-12-24 00:56:09,906 - src.lora_trainer - INFO -   (No validation data)
2025-12-24 00:56:09,906 - src.lora_trainer - INFO -   Learning Rate: 1.69e-04
2025-12-24 00:56:09,906 - src.lora_trainer - INFO - ============================================================

Epoch 2/3:   0%|          | 0/44 [00:00<?, ?it/s]Epoch 2/3:   0%|          | 0/44 [00:02<?, ?it/s, loss=0.0869]Epoch 2/3:   2%|▏         | 1/44 [00:02<02:03,  2.87s/it, loss=0.0869]Epoch 2/3:   2%|▏         | 1/44 [00:05<02:03,  2.87s/it, loss=0.0858]Epoch 2/3:   5%|▍         | 2/44 [00:05<01:58,  2.82s/it, loss=0.0858]Epoch 2/3:   5%|▍         | 2/44 [00:08<01:58,  2.82s/it, loss=0.0914]Epoch 2/3:   7%|▋         | 3/44 [00:08<01:56,  2.84s/it, loss=0.0914]Epoch 2/3:   7%|▋         | 3/44 [00:11<01:56,  2.84s/it, loss=0.1185]Epoch 2/3:   9%|▉         | 4/44 [00:11<01:53,  2.84s/it, loss=0.1185]Epoch 2/3:   9%|▉         | 4/44 [00:14<01:53,  2.84s/it, loss=0.0907]Epoch 2/3:  11%|█▏        | 5/44 [00:14<01:50,  2.83s/it, loss=0.0907]Epoch 2/3:  11%|█▏        | 5/44 [00:16<01:50,  2.83s/it, loss=0.0834]Epoch 2/3:  14%|█▎        | 6/44 [00:16<01:47,  2.83s/it, loss=0.0834]Epoch 2/3:  14%|█▎        | 6/44 [00:19<01:47,  2.83s/it, loss=0.1007]Epoch 2/3:  16%|█▌        | 7/44 [00:19<01:44,  2.82s/it, loss=0.1007]Epoch 2/3:  16%|█▌        | 7/44 [00:22<01:44,  2.82s/it, loss=0.0948]Epoch 2/3:  18%|█▊        | 8/44 [00:22<01:41,  2.82s/it, loss=0.0948]Epoch 2/3:  18%|█▊        | 8/44 [00:25<01:41,  2.82s/it, loss=0.0794]Epoch 2/3:  20%|██        | 9/44 [00:25<01:38,  2.81s/it, loss=0.0794]Epoch 2/3:  20%|██        | 9/44 [00:28<01:38,  2.81s/it, loss=0.0714]Epoch 2/3:  23%|██▎       | 10/44 [00:28<01:35,  2.82s/it, loss=0.0714]Epoch 2/3:  23%|██▎       | 10/44 [00:31<01:35,  2.82s/it, loss=0.0663]Epoch 2/3:  25%|██▌       | 11/44 [00:31<01:33,  2.82s/it, loss=0.0663]Epoch 2/3:  25%|██▌       | 11/44 [00:33<01:33,  2.82s/it, loss=0.0693]Epoch 2/3:  27%|██▋       | 12/44 [00:33<01:29,  2.81s/it, loss=0.0693]Epoch 2/3:  27%|██▋       | 12/44 [00:36<01:29,  2.81s/it, loss=0.0714]Epoch 2/3:  30%|██▉       | 13/44 [00:36<01:27,  2.82s/it, loss=0.0714]Epoch 2/3:  30%|██▉       | 13/44 [00:39<01:27,  2.82s/it, loss=0.0647]Epoch 2/3:  32%|███▏      | 14/44 [00:39<01:24,  2.82s/it, loss=0.0647]Epoch 2/3:  32%|███▏      | 14/44 [00:40<01:24,  2.82s/it, loss=0.2153]Epoch 2/3:  34%|███▍      | 15/44 [00:40<01:04,  2.24s/it, loss=0.2153]Epoch 2/3:  34%|███▍      | 15/44 [00:43<01:04,  2.24s/it, loss=0.0784]Epoch 2/3:  36%|███▋      | 16/44 [00:43<01:08,  2.43s/it, loss=0.0784]Epoch 2/3:  36%|███▋      | 16/44 [00:44<01:08,  2.43s/it, loss=0.2228]Epoch 2/3:  39%|███▊      | 17/44 [00:44<00:52,  1.93s/it, loss=0.2228]Epoch 2/3:  39%|███▊      | 17/44 [00:46<00:52,  1.93s/it, loss=0.0760]Epoch 2/3:  41%|████      | 18/44 [00:46<00:56,  2.19s/it, loss=0.0760]Epoch 2/3:  41%|████      | 18/44 [00:49<00:56,  2.19s/it, loss=0.0742]Epoch 2/3:  43%|████▎     | 19/44 [00:49<00:59,  2.38s/it, loss=0.0742]Epoch 2/3:  43%|████▎     | 19/44 [00:52<00:59,  2.38s/it, loss=0.0487]Epoch 2/3:  45%|████▌     | 20/44 [00:52<01:00,  2.52s/it, loss=0.0487]Epoch 2/3:  45%|████▌     | 20/44 [00:55<01:00,  2.52s/it, loss=0.0752]Epoch 2/3:  48%|████▊     | 21/44 [00:55<01:00,  2.61s/it, loss=0.0752]Epoch 2/3:  48%|████▊     | 21/44 [00:58<01:00,  2.61s/it, loss=0.0712]Epoch 2/3:  50%|█████     | 22/44 [00:58<00:58,  2.68s/it, loss=0.0712]Epoch 2/3:  50%|█████     | 22/44 [01:01<00:58,  2.68s/it, loss=0.0578]Epoch 2/3:  52%|█████▏    | 23/44 [01:01<00:57,  2.73s/it, loss=0.0578]Epoch 2/3:  52%|█████▏    | 23/44 [01:03<00:57,  2.73s/it, loss=0.0690]Epoch 2/3:  55%|█████▍    | 24/44 [01:03<00:55,  2.77s/it, loss=0.0690]Epoch 2/3:  55%|█████▍    | 24/44 [01:06<00:55,  2.77s/it, loss=0.0505]Epoch 2/3:  57%|█████▋    | 25/44 [01:06<00:52,  2.78s/it, loss=0.0505]Epoch 2/3:  57%|█████▋    | 25/44 [01:09<00:52,  2.78s/it, loss=0.0534]Epoch 2/3:  59%|█████▉    | 26/44 [01:09<00:50,  2.80s/it, loss=0.0534]Epoch 2/3:  59%|█████▉    | 26/44 [01:12<00:50,  2.80s/it, loss=0.0839]Epoch 2/3:  61%|██████▏   | 27/44 [01:12<00:48,  2.83s/it, loss=0.0839]Epoch 2/3:  61%|██████▏   | 27/44 [01:15<00:48,  2.83s/it, loss=0.0530]Epoch 2/3:  64%|██████▎   | 28/44 [01:15<00:45,  2.84s/it, loss=0.0530]Epoch 2/3:  64%|██████▎   | 28/44 [01:18<00:45,  2.84s/it, loss=0.0574]Epoch 2/3:  66%|██████▌   | 29/44 [01:18<00:42,  2.84s/it, loss=0.0574]Epoch 2/3:  66%|██████▌   | 29/44 [01:20<00:42,  2.84s/it, loss=0.0498]Epoch 2/3:  68%|██████▊   | 30/44 [01:20<00:39,  2.83s/it, loss=0.0498]Epoch 2/3:  68%|██████▊   | 30/44 [01:23<00:39,  2.83s/it, loss=0.0477]Epoch 2/3:  70%|███████   | 31/44 [01:23<00:36,  2.84s/it, loss=0.0477]Epoch 2/3:  70%|███████   | 31/44 [01:26<00:36,  2.84s/it, loss=0.0903]Epoch 2/3:  73%|███████▎  | 32/44 [01:26<00:34,  2.84s/it, loss=0.0903]Epoch 2/3:  73%|███████▎  | 32/44 [01:29<00:34,  2.84s/it, loss=0.0658]Epoch 2/3:  75%|███████▌  | 33/44 [01:29<00:31,  2.88s/it, loss=0.0658]Epoch 2/3:  75%|███████▌  | 33/44 [01:32<00:31,  2.88s/it, loss=0.0586]Epoch 2/3:  77%|███████▋  | 34/44 [01:32<00:28,  2.87s/it, loss=0.0586]Epoch 2/3:  77%|███████▋  | 34/44 [01:35<00:28,  2.87s/it, loss=0.0611]Epoch 2/3:  80%|███████▉  | 35/44 [01:35<00:25,  2.85s/it, loss=0.0611]Epoch 2/3:  80%|███████▉  | 35/44 [01:38<00:25,  2.85s/it, loss=0.0521]Epoch 2/3:  82%|████████▏ | 36/44 [01:38<00:22,  2.86s/it, loss=0.0521]Epoch 2/3:  82%|████████▏ | 36/44 [01:40<00:22,  2.86s/it, loss=0.0655]Epoch 2/3:  84%|████████▍ | 37/44 [01:40<00:19,  2.85s/it, loss=0.0655]Epoch 2/3:  84%|████████▍ | 37/44 [01:43<00:19,  2.85s/it, loss=0.0461]Epoch 2/3:  86%|████████▋ | 38/44 [01:43<00:17,  2.84s/it, loss=0.0461]Epoch 2/3:  86%|████████▋ | 38/44 [01:46<00:17,  2.84s/it, loss=0.0498]Epoch 2/3:  89%|████████▊ | 39/44 [01:46<00:14,  2.85s/it, loss=0.0498]Epoch 2/3:  89%|████████▊ | 39/44 [01:49<00:14,  2.85s/it, loss=0.0631]Epoch 2/3:  91%|█████████ | 40/44 [01:49<00:11,  2.84s/it, loss=0.0631]Epoch 2/3:  91%|█████████ | 40/44 [01:52<00:11,  2.84s/it, loss=0.0621]Epoch 2/3:  93%|█████████▎| 41/44 [01:52<00:08,  2.84s/it, loss=0.0621]Epoch 2/3:  93%|█████████▎| 41/44 [01:55<00:08,  2.84s/it, loss=0.0528]Epoch 2/3:  95%|█████████▌| 42/44 [01:55<00:05,  2.84s/it, loss=0.0528]Epoch 2/3:  95%|█████████▌| 42/44 [01:57<00:05,  2.84s/it, loss=0.0522]Epoch 2/3:  98%|█████████▊| 43/44 [01:57<00:02,  2.82s/it, loss=0.0522]Epoch 2/3:  98%|█████████▊| 43/44 [01:59<00:02,  2.82s/it, loss=0.0745]Epoch 2/3: 100%|██████████| 44/44 [01:59<00:00,  2.47s/it, loss=0.0745]Epoch 2/3: 100%|██████████| 44/44 [01:59<00:00,  2.72s/it, loss=0.0745]
2025-12-24 00:58:09,475 - src.lora_trainer - INFO - 
============================================================
2025-12-24 00:58:09,476 - src.lora_trainer - INFO - Epoch 2/3 Summary
2025-12-24 00:58:09,476 - src.lora_trainer - INFO - ============================================================
2025-12-24 00:58:09,476 - src.lora_trainer - INFO -   Train Loss:    0.0762
2025-12-24 00:58:09,476 - src.lora_trainer - INFO -   (No validation data)
2025-12-24 00:58:09,476 - src.lora_trainer - INFO -   Learning Rate: 1.97e-04
2025-12-24 00:58:09,476 - src.lora_trainer - INFO - ============================================================

Epoch 3/3:   0%|          | 0/44 [00:00<?, ?it/s]Epoch 3/3:   0%|          | 0/44 [00:02<?, ?it/s, loss=0.0439]Epoch 3/3:   2%|▏         | 1/44 [00:02<02:01,  2.82s/it, loss=0.0439]Epoch 3/3:   2%|▏         | 1/44 [00:05<02:01,  2.82s/it, loss=0.0594]Epoch 3/3:   5%|▍         | 2/44 [00:05<01:52,  2.69s/it, loss=0.0594]Epoch 3/3:   5%|▍         | 2/44 [00:08<01:52,  2.69s/it, loss=0.0545]Epoch 3/3:   7%|▋         | 3/44 [00:08<01:52,  2.74s/it, loss=0.0545]Epoch 3/3:   7%|▋         | 3/44 [00:11<01:52,  2.74s/it, loss=0.0618]Epoch 3/3:   9%|▉         | 4/44 [00:11<01:50,  2.77s/it, loss=0.0618]Epoch 3/3:   9%|▉         | 4/44 [00:13<01:50,  2.77s/it, loss=0.0424]Epoch 3/3:  11%|█▏        | 5/44 [00:13<01:48,  2.78s/it, loss=0.0424]Epoch 3/3:  11%|█▏        | 5/44 [00:16<01:48,  2.78s/it, loss=0.0457]Epoch 3/3:  14%|█▎        | 6/44 [00:16<01:46,  2.79s/it, loss=0.0457]Epoch 3/3:  14%|█▎        | 6/44 [00:19<01:46,  2.79s/it, loss=0.0407]Epoch 3/3:  16%|█▌        | 7/44 [00:19<01:43,  2.80s/it, loss=0.0407]Epoch 3/3:  16%|█▌        | 7/44 [00:22<01:43,  2.80s/it, loss=0.0536]Epoch 3/3:  18%|█▊        | 8/44 [00:22<01:40,  2.80s/it, loss=0.0536]Epoch 3/3:  18%|█▊        | 8/44 [00:25<01:40,  2.80s/it, loss=0.0456]Epoch 3/3:  20%|██        | 9/44 [00:25<01:37,  2.80s/it, loss=0.0456]Epoch 3/3:  20%|██        | 9/44 [00:27<01:37,  2.80s/it, loss=0.0529]Epoch 3/3:  23%|██▎       | 10/44 [00:27<01:35,  2.80s/it, loss=0.0529]Epoch 3/3:  23%|██▎       | 10/44 [00:30<01:35,  2.80s/it, loss=0.0545]Epoch 3/3:  25%|██▌       | 11/44 [00:30<01:32,  2.82s/it, loss=0.0545]Epoch 3/3:  25%|██▌       | 11/44 [00:33<01:32,  2.82s/it, loss=0.0445]Epoch 3/3:  27%|██▋       | 12/44 [00:33<01:30,  2.82s/it, loss=0.0445]Epoch 3/3:  27%|██▋       | 12/44 [00:36<01:30,  2.82s/it, loss=0.0461]Epoch 3/3:  30%|██▉       | 13/44 [00:36<01:27,  2.82s/it, loss=0.0461]Epoch 3/3:  30%|██▉       | 13/44 [00:39<01:27,  2.82s/it, loss=0.0375]Epoch 3/3:  32%|███▏      | 14/44 [00:39<01:24,  2.82s/it, loss=0.0375]Epoch 3/3:  32%|███▏      | 14/44 [00:42<01:24,  2.82s/it, loss=0.0372]Epoch 3/3:  34%|███▍      | 15/44 [00:42<01:21,  2.82s/it, loss=0.0372]Epoch 3/3:  34%|███▍      | 15/44 [00:44<01:21,  2.82s/it, loss=0.0495]Epoch 3/3:  36%|███▋      | 16/44 [00:44<01:18,  2.82s/it, loss=0.0495]Epoch 3/3:  36%|███▋      | 16/44 [00:47<01:18,  2.82s/it, loss=0.0494]Epoch 3/3:  39%|███▊      | 17/44 [00:47<01:16,  2.83s/it, loss=0.0494]Epoch 3/3:  39%|███▊      | 17/44 [00:50<01:16,  2.83s/it, loss=0.0466]Epoch 3/3:  41%|████      | 18/44 [00:50<01:13,  2.84s/it, loss=0.0466]Epoch 3/3:  41%|████      | 18/44 [00:53<01:13,  2.84s/it, loss=0.0419]Epoch 3/3:  43%|████▎     | 19/44 [00:53<01:11,  2.84s/it, loss=0.0419]Epoch 3/3:  43%|████▎     | 19/44 [00:56<01:11,  2.84s/it, loss=0.0385]Epoch 3/3:  45%|████▌     | 20/44 [00:56<01:08,  2.85s/it, loss=0.0385]Epoch 3/3:  45%|████▌     | 20/44 [00:59<01:08,  2.85s/it, loss=0.0433]Epoch 3/3:  48%|████▊     | 21/44 [00:59<01:05,  2.86s/it, loss=0.0433]Epoch 3/3:  48%|████▊     | 21/44 [01:01<01:05,  2.86s/it, loss=0.0325]Epoch 3/3:  50%|█████     | 22/44 [01:01<01:02,  2.83s/it, loss=0.0325]Epoch 3/3:  50%|█████     | 22/44 [01:04<01:02,  2.83s/it, loss=0.0337]Epoch 3/3:  52%|█████▏    | 23/44 [01:04<00:59,  2.84s/it, loss=0.0337]Epoch 3/3:  52%|█████▏    | 23/44 [01:07<00:59,  2.84s/it, loss=0.0297]Epoch 3/3:  55%|█████▍    | 24/44 [01:07<00:56,  2.83s/it, loss=0.0297]Epoch 3/3:  55%|█████▍    | 24/44 [01:10<00:56,  2.83s/it, loss=0.0353]Epoch 3/3:  57%|█████▋    | 25/44 [01:10<00:53,  2.84s/it, loss=0.0353]Epoch 3/3:  57%|█████▋    | 25/44 [01:12<00:53,  2.84s/it, loss=0.0494]Epoch 3/3:  59%|█████▉    | 26/44 [01:12<00:47,  2.65s/it, loss=0.0494]Epoch 3/3:  59%|█████▉    | 26/44 [01:15<00:47,  2.65s/it, loss=0.0366]Epoch 3/3:  61%|██████▏   | 27/44 [01:15<00:45,  2.70s/it, loss=0.0366]Epoch 3/3:  61%|██████▏   | 27/44 [01:18<00:45,  2.70s/it, loss=0.0352]Epoch 3/3:  64%|██████▎   | 28/44 [01:18<00:43,  2.73s/it, loss=0.0352]Epoch 3/3:  64%|██████▎   | 28/44 [01:21<00:43,  2.73s/it, loss=1.9678]Epoch 3/3:  66%|██████▌   | 29/44 [01:21<00:41,  2.76s/it, loss=1.9678]Epoch 3/3:  66%|██████▌   | 29/44 [01:23<00:41,  2.76s/it, loss=1.9714]Epoch 3/3:  68%|██████▊   | 30/44 [01:23<00:38,  2.76s/it, loss=1.9714]Epoch 3/3:  68%|██████▊   | 30/44 [01:26<00:38,  2.76s/it, loss=1.9014]Epoch 3/3:  70%|███████   | 31/44 [01:26<00:35,  2.77s/it, loss=1.9014]Epoch 3/3:  70%|███████   | 31/44 [01:29<00:35,  2.77s/it, loss=1.9653]Epoch 3/3:  73%|███████▎  | 32/44 [01:29<00:33,  2.78s/it, loss=1.9653]Epoch 3/3:  73%|███████▎  | 32/44 [01:32<00:33,  2.78s/it, loss=0.0417]Epoch 3/3:  75%|███████▌  | 33/44 [01:32<00:30,  2.78s/it, loss=0.0417]Epoch 3/3:  75%|███████▌  | 33/44 [01:35<00:30,  2.78s/it, loss=0.0396]Epoch 3/3:  77%|███████▋  | 34/44 [01:35<00:27,  2.78s/it, loss=0.0396]Epoch 3/3:  77%|███████▋  | 34/44 [01:37<00:27,  2.78s/it, loss=0.0402]Epoch 3/3:  80%|███████▉  | 35/44 [01:37<00:25,  2.80s/it, loss=0.0402]Epoch 3/3:  80%|███████▉  | 35/44 [01:40<00:25,  2.80s/it, loss=0.0485]Epoch 3/3:  82%|████████▏ | 36/44 [01:40<00:22,  2.82s/it, loss=0.0485]Epoch 3/3:  82%|████████▏ | 36/44 [01:43<00:22,  2.82s/it, loss=0.0425]Epoch 3/3:  84%|████████▍ | 37/44 [01:43<00:19,  2.82s/it, loss=0.0425]Epoch 3/3:  84%|████████▍ | 37/44 [01:45<00:19,  2.82s/it, loss=0.0511]Epoch 3/3:  86%|████████▋ | 38/44 [01:45<00:16,  2.71s/it, loss=0.0511]Epoch 3/3:  86%|████████▋ | 38/44 [01:48<00:16,  2.71s/it, loss=0.0492]Epoch 3/3:  89%|████████▊ | 39/44 [01:48<00:13,  2.75s/it, loss=0.0492]Epoch 3/3:  89%|████████▊ | 39/44 [01:51<00:13,  2.75s/it, loss=0.0505]Epoch 3/3:  91%|█████████ | 40/44 [01:51<00:11,  2.76s/it, loss=0.0505]Epoch 3/3:  91%|█████████ | 40/44 [01:54<00:11,  2.76s/it, loss=0.0348]Epoch 3/3:  93%|█████████▎| 41/44 [01:54<00:08,  2.79s/it, loss=0.0348]Epoch 3/3:  93%|█████████▎| 41/44 [01:57<00:08,  2.79s/it, loss=0.0341]Epoch 3/3:  95%|█████████▌| 42/44 [01:57<00:05,  2.79s/it, loss=0.0341]Epoch 3/3:  95%|█████████▌| 42/44 [02:00<00:05,  2.79s/it, loss=0.0403]Epoch 3/3:  98%|█████████▊| 43/44 [02:00<00:02,  2.80s/it, loss=0.0403]Epoch 3/3:  98%|█████████▊| 43/44 [02:02<00:02,  2.80s/it, loss=0.0309]Epoch 3/3: 100%|██████████| 44/44 [02:02<00:00,  2.60s/it, loss=0.0309]Epoch 3/3: 100%|██████████| 44/44 [02:02<00:00,  2.78s/it, loss=0.0309]
2025-12-24 01:00:11,731 - src.lora_trainer - INFO - 
============================================================
2025-12-24 01:00:11,732 - src.lora_trainer - INFO - Epoch 3/3 Summary
2025-12-24 01:00:11,732 - src.lora_trainer - INFO - ============================================================
2025-12-24 01:00:11,732 - src.lora_trainer - INFO -   Train Loss:    0.2171
2025-12-24 01:00:11,732 - src.lora_trainer - INFO -   (No validation data)
2025-12-24 01:00:11,732 - src.lora_trainer - INFO -   Learning Rate: 1.86e-04
2025-12-24 01:00:11,732 - src.lora_trainer - INFO - ============================================================

2025-12-24 01:00:11,732 - src.lora_trainer - INFO - Training completed. Average loss: 0.2289
2025-12-24 01:00:12,249 - src.lora_trainer - INFO - ✓ Training curves saved to: logs/training_curves/benign_20251224_010011.png
2025-12-24 01:00:12,249 - src.lora_trainer - INFO - ✓ Training data saved to: logs/training_curves/benign_20251224_010011.csv
2025-12-24 01:00:12,431 - src.lora_trainer - INFO - ✓ Extracted 448 LoRA parameters
2025-12-24 01:00:12,431 - __main__ - INFO - 
Saving A7 adapter...
2025-12-24 01:00:12,649 - src.adapter_utils - INFO - ✓ Adapter saved to: saved_adapters/mistral-7b-v0.2/utility_model/utility_model_A7.pt
2025-12-24 01:00:12,650 - src.adapter_utils - INFO -   Metadata: {'type': 'utility_model_A7', 'task': 'security', 'model': 'mistral-7b-v0.2', 'note': 'Security instruction-response model'}
2025-12-24 01:00:12,650 - __main__ - INFO - 
✓ A7 adapter saved to: saved_adapters/mistral-7b-v0.2/utility_model/utility_model_A7.pt
2025-12-24 01:00:12,650 - __main__ - INFO - 
================================================================================
2025-12-24 01:00:12,650 - __main__ - INFO - A7 (Security) MODEL CREATION COMPLETED
2025-12-24 01:00:12,650 - __main__ - INFO - ================================================================================
2025-12-24 01:00:12,650 - __main__ - INFO - 
Note: Evaluation will be performed separately using evaluate_all_models.py
