/mnt/iag-02/home/hiromi/src/SST_merge/sst/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-12-23 20:50:53,279 - __main__ - INFO - 
================================================================================
2025-12-23 20:50:53,279 - __main__ - INFO - A7 (Security) MODEL CREATION
2025-12-23 20:50:53,279 - __main__ - INFO - ================================================================================
2025-12-23 20:50:53,279 - __main__ - INFO - 
Loading training dataset...
2025-12-23 20:50:53,431 - src.utils.instruction_loaders - INFO - Loading Security dataset from data/response_dataframe.csv...
2025-12-23 20:50:53,439 - src.utils.instruction_loaders - INFO - Loaded 1400 samples from Security dataset
2025-12-23 20:50:53,439 - src.utils.instruction_loaders - INFO - Created Security DataLoader: 1400 samples, batch_size=32
2025-12-23 20:50:53,440 - __main__ - INFO - ✓ Dataset loaded
2025-12-23 20:50:53,440 - __main__ - INFO - 
Loading model: llama-3.1-8b...
2025-12-23 20:50:53,440 - src.utils.model_loader - INFO - ModelLoader initialized: model=meta-llama/Llama-3.1-8B-Instruct, device_map=auto, dtype=torch.bfloat16
2025-12-23 20:50:53,440 - src.utils.model_loader - INFO - Loading model: meta-llama/Llama-3.1-8B-Instruct
2025-12-23 20:50:54,587 - src.utils.model_loader - INFO - Using Flash Attention 2 for faster inference
`torch_dtype` is deprecated! Use `dtype` instead!
2025-12-23 20:50:55,130 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.20it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.17it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.17it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.69it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
2025-12-23 20:50:58,263 - src.utils.model_loader - INFO - ✓ Model loaded successfully: meta-llama/Llama-3.1-8B-Instruct
2025-12-23 20:50:58,263 - src.utils.model_loader - INFO -   Total parameters: 8.03B
2025-12-23 20:50:58,263 - src.utils.model_loader - INFO -   Device map: {'': 0}
2025-12-23 20:50:58,263 - __main__ - INFO - ✓ Model loaded
2025-12-23 20:50:58,264 - __main__ - INFO - 
Fine-tuning on Security data...
2025-12-23 20:50:58,264 - src.lora_trainer - INFO - LoRATrainer initialized on device: cuda
2025-12-23 20:50:58,264 - src.lora_trainer - INFO - 
Training LoRA adapter for benign task...
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   Epochs: 3
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   Learning rate: 0.0002
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   LoRA rank: 32
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   LoRA alpha: 64
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   LoRA dropout: 0.0
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   Weight decay: 0.01
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   Warmup ratio: 0.1
2025-12-23 20:50:58,264 - src.lora_trainer - INFO -   Gradient accumulation steps: 4
2025-12-23 20:51:00,202 - src.lora_trainer - INFO -   Gradient checkpointing enabled
2025-12-23 20:51:00,213 - src.lora_trainer - INFO -   Total training steps: 132
2025-12-23 20:51:00,213 - src.lora_trainer - INFO -   Warmup steps: 13
/mnt/iag-02/home/hiromi/src/SST_merge/src/lora_trainer.py:206: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
2025-12-23 20:51:00,213 - src.lora_trainer - INFO -   Mixed precision training enabled
Epoch 1/3:   0%|          | 0/44 [00:00<?, ?it/s]/mnt/iag-02/home/hiromi/src/SST_merge/src/lora_trainer.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast():
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
Casting fp32 inputs back to torch.float16 for flash-attn compatibility.
Epoch 1/3:   0%|          | 0/44 [00:02<?, ?it/s, loss=3.8885]Epoch 1/3:   2%|▏         | 1/44 [00:02<02:07,  2.97s/it, loss=3.8885]Epoch 1/3:   2%|▏         | 1/44 [00:05<02:07,  2.97s/it, loss=3.9058]Epoch 1/3:   5%|▍         | 2/44 [00:05<01:56,  2.78s/it, loss=3.9058]Epoch 1/3:   5%|▍         | 2/44 [00:08<01:56,  2.78s/it, loss=3.8997]Epoch 1/3:   7%|▋         | 3/44 [00:08<01:51,  2.73s/it, loss=3.8997]Epoch 1/3:   7%|▋         | 3/44 [00:10<01:51,  2.73s/it, loss=3.9136]Epoch 1/3:   9%|▉         | 4/44 [00:10<01:47,  2.70s/it, loss=3.9136]Epoch 1/3:   9%|▉         | 4/44 [00:11<01:47,  2.70s/it, loss=3.4354]Epoch 1/3:  11%|█▏        | 5/44 [00:11<01:19,  2.04s/it, loss=3.4354]Epoch 1/3:  11%|█▏        | 5/44 [00:14<01:19,  2.04s/it, loss=3.9069]Epoch 1/3:  14%|█▎        | 6/44 [00:14<01:25,  2.25s/it, loss=3.9069]Epoch 1/3:  14%|█▎        | 6/44 [00:17<01:25,  2.25s/it, loss=3.8929]Epoch 1/3:  16%|█▌        | 7/44 [00:17<01:31,  2.47s/it, loss=3.8929]Epoch 1/3:  16%|█▌        | 7/44 [00:20<01:31,  2.47s/it, loss=3.9015]Epoch 1/3:  18%|█▊        | 8/44 [00:20<01:31,  2.54s/it, loss=3.9015]Epoch 1/3:  18%|█▊        | 8/44 [00:21<01:31,  2.54s/it, loss=3.4912]Epoch 1/3:  20%|██        | 9/44 [00:21<01:11,  2.04s/it, loss=3.4912]Epoch 1/3:  20%|██        | 9/44 [00:23<01:11,  2.04s/it, loss=3.8912]Epoch 1/3:  23%|██▎       | 10/44 [00:23<01:15,  2.22s/it, loss=3.8912]Epoch 1/3:  23%|██▎       | 10/44 [00:26<01:15,  2.22s/it, loss=3.8945]Epoch 1/3:  25%|██▌       | 11/44 [00:26<01:17,  2.35s/it, loss=3.8945]Epoch 1/3:  25%|██▌       | 11/44 [00:28<01:17,  2.35s/it, loss=3.9055]Epoch 1/3:  27%|██▋       | 12/44 [00:28<01:18,  2.45s/it, loss=3.9055]Epoch 1/3:  27%|██▋       | 12/44 [00:31<01:18,  2.45s/it, loss=3.9813]Epoch 1/3:  30%|██▉       | 13/44 [00:31<01:13,  2.38s/it, loss=3.9813]Epoch 1/3:  30%|██▉       | 13/44 [00:33<01:13,  2.38s/it, loss=4.0153]Epoch 1/3:  32%|███▏      | 14/44 [00:33<01:13,  2.45s/it, loss=4.0153]Epoch 1/3:  32%|███▏      | 14/44 [00:36<01:13,  2.45s/it, loss=4.0174]Epoch 1/3:  34%|███▍      | 15/44 [00:36<01:12,  2.50s/it, loss=4.0174]Epoch 1/3:  34%|███▍      | 15/44 [00:39<01:12,  2.50s/it, loss=4.0095]Epoch 1/3:  36%|███▋      | 16/44 [00:39<01:11,  2.55s/it, loss=4.0095]Epoch 1/3:  36%|███▋      | 16/44 [00:41<01:11,  2.55s/it, loss=3.3504]Epoch 1/3:  39%|███▊      | 17/44 [00:41<01:09,  2.57s/it, loss=3.3504]Epoch 1/3:  39%|███▊      | 17/44 [00:43<01:09,  2.57s/it, loss=3.2957]Epoch 1/3:  41%|████      | 18/44 [00:43<01:00,  2.33s/it, loss=3.2957]Epoch 1/3:  41%|████      | 18/44 [00:46<01:00,  2.33s/it, loss=3.3533]Epoch 1/3:  43%|████▎     | 19/44 [00:46<01:00,  2.42s/it, loss=3.3533]Epoch 1/3:  43%|████▎     | 19/44 [00:48<01:00,  2.42s/it, loss=3.3427]Epoch 1/3:  45%|████▌     | 20/44 [00:48<00:59,  2.48s/it, loss=3.3427]Epoch 1/3:  45%|████▌     | 20/44 [00:51<00:59,  2.48s/it, loss=2.8017]Epoch 1/3:  48%|████▊     | 21/44 [00:51<00:58,  2.54s/it, loss=2.8017]Epoch 1/3:  48%|████▊     | 21/44 [00:54<00:58,  2.54s/it, loss=2.7889]Epoch 1/3:  50%|█████     | 22/44 [00:54<00:56,  2.58s/it, loss=2.7889]Epoch 1/3:  50%|█████     | 22/44 [00:56<00:56,  2.58s/it, loss=2.8111]Epoch 1/3:  52%|█████▏    | 23/44 [00:56<00:54,  2.60s/it, loss=2.8111]Epoch 1/3:  52%|█████▏    | 23/44 [00:59<00:54,  2.60s/it, loss=2.8104]Epoch 1/3:  55%|█████▍    | 24/44 [00:59<00:52,  2.62s/it, loss=2.8104]Epoch 1/3:  55%|█████▍    | 24/44 [01:02<00:52,  2.62s/it, loss=1.8189]Epoch 1/3:  57%|█████▋    | 25/44 [01:02<00:50,  2.64s/it, loss=1.8189]Epoch 1/3:  57%|█████▋    | 25/44 [01:04<00:50,  2.64s/it, loss=1.8129]Epoch 1/3:  59%|█████▉    | 26/44 [01:04<00:47,  2.65s/it, loss=1.8129]Epoch 1/3:  59%|█████▉    | 26/44 [01:07<00:47,  2.65s/it, loss=1.8200]Epoch 1/3:  61%|██████▏   | 27/44 [01:07<00:45,  2.65s/it, loss=1.8200]Epoch 1/3:  61%|██████▏   | 27/44 [01:10<00:45,  2.65s/it, loss=1.8236]Epoch 1/3:  64%|██████▎   | 28/44 [01:10<00:42,  2.64s/it, loss=1.8236]Epoch 1/3:  64%|██████▎   | 28/44 [01:12<00:42,  2.64s/it, loss=0.3741]Epoch 1/3:  66%|██████▌   | 29/44 [01:12<00:39,  2.64s/it, loss=0.3741]Epoch 1/3:  66%|██████▌   | 29/44 [01:15<00:39,  2.64s/it, loss=0.3749]Epoch 1/3:  68%|██████▊   | 30/44 [01:15<00:36,  2.64s/it, loss=0.3749]Epoch 1/3:  68%|██████▊   | 30/44 [01:17<00:36,  2.64s/it, loss=0.3755]Epoch 1/3:  70%|███████   | 31/44 [01:17<00:34,  2.64s/it, loss=0.3755]Epoch 1/3:  70%|███████   | 31/44 [01:20<00:34,  2.64s/it, loss=0.3754]Epoch 1/3:  73%|███████▎  | 32/44 [01:20<00:31,  2.64s/it, loss=0.3754]Epoch 1/3:  73%|███████▎  | 32/44 [01:23<00:31,  2.64s/it, loss=0.0126]Epoch 1/3:  75%|███████▌  | 33/44 [01:23<00:29,  2.64s/it, loss=0.0126]Epoch 1/3:  75%|███████▌  | 33/44 [01:25<00:29,  2.64s/it, loss=0.0132]Epoch 1/3:  77%|███████▋  | 34/44 [01:25<00:26,  2.65s/it, loss=0.0132]Epoch 1/3:  77%|███████▋  | 34/44 [01:28<00:26,  2.65s/it, loss=0.0132]Epoch 1/3:  80%|███████▉  | 35/44 [01:28<00:23,  2.64s/it, loss=0.0132]Epoch 1/3:  80%|███████▉  | 35/44 [01:31<00:23,  2.64s/it, loss=0.0131]Epoch 1/3:  82%|████████▏ | 36/44 [01:31<00:21,  2.64s/it, loss=0.0131]Epoch 1/3:  82%|████████▏ | 36/44 [01:33<00:21,  2.64s/it, loss=0.0074]Epoch 1/3:  84%|████████▍ | 37/44 [01:33<00:18,  2.64s/it, loss=0.0074]Epoch 1/3:  84%|████████▍ | 37/44 [01:36<00:18,  2.64s/it, loss=0.0076]Epoch 1/3:  86%|████████▋ | 38/44 [01:36<00:15,  2.65s/it, loss=0.0076]Epoch 1/3:  86%|████████▋ | 38/44 [01:39<00:15,  2.65s/it, loss=0.0069]Epoch 1/3:  89%|████████▊ | 39/44 [01:39<00:13,  2.63s/it, loss=0.0069]Epoch 1/3:  89%|████████▊ | 39/44 [01:41<00:13,  2.63s/it, loss=0.0071]Epoch 1/3:  91%|█████████ | 40/44 [01:41<00:10,  2.65s/it, loss=0.0071]Epoch 1/3:  91%|█████████ | 40/44 [01:44<00:10,  2.65s/it, loss=0.0046]Epoch 1/3:  93%|█████████▎| 41/44 [01:44<00:07,  2.64s/it, loss=0.0046]Epoch 1/3:  93%|█████████▎| 41/44 [01:47<00:07,  2.64s/it, loss=0.0048]Epoch 1/3:  95%|█████████▌| 42/44 [01:47<00:05,  2.66s/it, loss=0.0048]Epoch 1/3:  95%|█████████▌| 42/44 [01:49<00:05,  2.66s/it, loss=0.0045]Epoch 1/3:  98%|█████████▊| 43/44 [01:49<00:02,  2.64s/it, loss=0.0045]Epoch 1/3:  98%|█████████▊| 43/44 [01:51<00:02,  2.64s/it, loss=0.0045]Epoch 1/3: 100%|██████████| 44/44 [01:51<00:00,  2.45s/it, loss=0.0045]Epoch 1/3: 100%|██████████| 44/44 [01:51<00:00,  2.54s/it, loss=0.0045]
2025-12-23 20:52:51,875 - src.lora_trainer - INFO - 
============================================================
2025-12-23 20:52:51,875 - src.lora_trainer - INFO - Epoch 1/3 Summary
2025-12-23 20:52:51,875 - src.lora_trainer - INFO - ============================================================
2025-12-23 20:52:51,875 - src.lora_trainer - INFO -   Train Loss:    2.1677
2025-12-23 20:52:51,875 - src.lora_trainer - INFO -   (No validation data)
2025-12-23 20:52:51,875 - src.lora_trainer - INFO -   Learning Rate: 1.69e-04
2025-12-23 20:52:51,875 - src.lora_trainer - INFO - ============================================================

Epoch 2/3:   0%|          | 0/44 [00:00<?, ?it/s]Epoch 2/3:   0%|          | 0/44 [00:02<?, ?it/s, loss=0.0080]Epoch 2/3:   2%|▏         | 1/44 [00:02<01:52,  2.61s/it, loss=0.0080]Epoch 2/3:   2%|▏         | 1/44 [00:05<01:52,  2.61s/it, loss=0.0082]Epoch 2/3:   5%|▍         | 2/44 [00:05<01:51,  2.64s/it, loss=0.0082]Epoch 2/3:   5%|▍         | 2/44 [00:07<01:51,  2.64s/it, loss=0.0086]Epoch 2/3:   7%|▋         | 3/44 [00:07<01:47,  2.62s/it, loss=0.0086]Epoch 2/3:   7%|▋         | 3/44 [00:10<01:47,  2.62s/it, loss=0.0090]Epoch 2/3:   9%|▉         | 4/44 [00:10<01:46,  2.65s/it, loss=0.0090]Epoch 2/3:   9%|▉         | 4/44 [00:13<01:46,  2.65s/it, loss=0.0049]Epoch 2/3:  11%|█▏        | 5/44 [00:13<01:43,  2.66s/it, loss=0.0049]Epoch 2/3:  11%|█▏        | 5/44 [00:15<01:43,  2.66s/it, loss=0.0052]Epoch 2/3:  14%|█▎        | 6/44 [00:15<01:41,  2.66s/it, loss=0.0052]Epoch 2/3:  14%|█▎        | 6/44 [00:18<01:41,  2.66s/it, loss=0.0052]Epoch 2/3:  16%|█▌        | 7/44 [00:18<01:37,  2.63s/it, loss=0.0052]Epoch 2/3:  16%|█▌        | 7/44 [00:21<01:37,  2.63s/it, loss=0.0051]Epoch 2/3:  18%|█▊        | 8/44 [00:21<01:34,  2.63s/it, loss=0.0051]Epoch 2/3:  18%|█▊        | 8/44 [00:23<01:34,  2.63s/it, loss=0.5343]Epoch 2/3:  20%|██        | 9/44 [00:23<01:32,  2.64s/it, loss=0.5343]Epoch 2/3:  20%|██        | 9/44 [00:26<01:32,  2.64s/it, loss=0.5323]Epoch 2/3:  23%|██▎       | 10/44 [00:26<01:30,  2.65s/it, loss=0.5323]Epoch 2/3:  23%|██▎       | 10/44 [00:29<01:30,  2.65s/it, loss=0.5341]Epoch 2/3:  25%|██▌       | 11/44 [00:29<01:27,  2.66s/it, loss=0.5341]Epoch 2/3:  25%|██▌       | 11/44 [00:31<01:27,  2.66s/it, loss=0.5338]Epoch 2/3:  27%|██▋       | 12/44 [00:31<01:24,  2.64s/it, loss=0.5338]Epoch 2/3:  27%|██▋       | 12/44 [00:34<01:24,  2.64s/it, loss=0.5334]Epoch 2/3:  30%|██▉       | 13/44 [00:34<01:21,  2.63s/it, loss=0.5334]Epoch 2/3:  30%|██▉       | 13/44 [00:36<01:21,  2.63s/it, loss=0.5346]Epoch 2/3:  32%|███▏      | 14/44 [00:36<01:18,  2.63s/it, loss=0.5346]Epoch 2/3:  32%|███▏      | 14/44 [00:39<01:18,  2.63s/it, loss=0.5316]Epoch 2/3:  34%|███▍      | 15/44 [00:39<01:16,  2.63s/it, loss=0.5316]Epoch 2/3:  34%|███▍      | 15/44 [00:42<01:16,  2.63s/it, loss=0.5332]Epoch 2/3:  36%|███▋      | 16/44 [00:42<01:13,  2.64s/it, loss=0.5332]Epoch 2/3:  36%|███▋      | 16/44 [00:44<01:13,  2.64s/it, loss=1.1092]Epoch 2/3:  39%|███▊      | 17/44 [00:44<01:11,  2.63s/it, loss=1.1092]Epoch 2/3:  39%|███▊      | 17/44 [00:47<01:11,  2.63s/it, loss=1.1098]Epoch 2/3:  41%|████      | 18/44 [00:47<01:08,  2.64s/it, loss=1.1098]Epoch 2/3:  41%|████      | 18/44 [00:50<01:08,  2.64s/it, loss=1.1088]Epoch 2/3:  43%|████▎     | 19/44 [00:50<01:06,  2.64s/it, loss=1.1088]Epoch 2/3:  43%|████▎     | 19/44 [00:52<01:06,  2.64s/it, loss=1.1087]Epoch 2/3:  45%|████▌     | 20/44 [00:52<01:03,  2.65s/it, loss=1.1087]Epoch 2/3:  45%|████▌     | 20/44 [00:55<01:03,  2.65s/it, loss=0.0270]Epoch 2/3:  48%|████▊     | 21/44 [00:55<01:00,  2.63s/it, loss=0.0270]Epoch 2/3:  48%|████▊     | 21/44 [00:58<01:00,  2.63s/it, loss=0.0270]Epoch 2/3:  50%|█████     | 22/44 [00:58<00:57,  2.62s/it, loss=0.0270]Epoch 2/3:  50%|█████     | 22/44 [01:00<00:57,  2.62s/it, loss=0.0269]Epoch 2/3:  52%|█████▏    | 23/44 [01:00<00:54,  2.61s/it, loss=0.0269]Epoch 2/3:  52%|█████▏    | 23/44 [01:03<00:54,  2.61s/it, loss=0.0272]Epoch 2/3:  55%|█████▍    | 24/44 [01:03<00:52,  2.62s/it, loss=0.0272]Epoch 2/3:  55%|█████▍    | 24/44 [01:05<00:52,  2.62s/it, loss=0.0018]Epoch 2/3:  57%|█████▋    | 25/44 [01:05<00:49,  2.61s/it, loss=0.0018]Epoch 2/3:  57%|█████▋    | 25/44 [01:08<00:49,  2.61s/it, loss=0.0020]Epoch 2/3:  59%|█████▉    | 26/44 [01:08<00:47,  2.63s/it, loss=0.0020]Epoch 2/3:  59%|█████▉    | 26/44 [01:11<00:47,  2.63s/it, loss=0.0019]Epoch 2/3:  61%|██████▏   | 27/44 [01:11<00:44,  2.63s/it, loss=0.0019]Epoch 2/3:  61%|██████▏   | 27/44 [01:13<00:44,  2.63s/it, loss=0.0021]Epoch 2/3:  64%|██████▎   | 28/44 [01:13<00:42,  2.64s/it, loss=0.0021]Epoch 2/3:  64%|██████▎   | 28/44 [01:16<00:42,  2.64s/it, loss=0.0009]Epoch 2/3:  66%|██████▌   | 29/44 [01:16<00:39,  2.63s/it, loss=0.0009]Epoch 2/3:  66%|██████▌   | 29/44 [01:19<00:39,  2.63s/it, loss=0.0012]Epoch 2/3:  68%|██████▊   | 30/44 [01:19<00:36,  2.64s/it, loss=0.0012]Epoch 2/3:  68%|██████▊   | 30/44 [01:21<00:36,  2.64s/it, loss=0.0016]Epoch 2/3:  70%|███████   | 31/44 [01:21<00:34,  2.64s/it, loss=0.0016]Epoch 2/3:  70%|███████   | 31/44 [01:24<00:34,  2.64s/it, loss=0.0012]Epoch 2/3:  73%|███████▎  | 32/44 [01:24<00:31,  2.65s/it, loss=0.0012]Epoch 2/3:  73%|███████▎  | 32/44 [01:27<00:31,  2.65s/it, loss=0.0006]Epoch 2/3:  75%|███████▌  | 33/44 [01:27<00:29,  2.65s/it, loss=0.0006]Epoch 2/3:  75%|███████▌  | 33/44 [01:29<00:29,  2.65s/it, loss=0.0014]Epoch 2/3:  77%|███████▋  | 34/44 [01:29<00:26,  2.62s/it, loss=0.0014]Epoch 2/3:  77%|███████▋  | 34/44 [01:32<00:26,  2.62s/it, loss=0.0010]Epoch 2/3:  80%|███████▉  | 35/44 [01:32<00:23,  2.62s/it, loss=0.0010]Epoch 2/3:  80%|███████▉  | 35/44 [01:35<00:23,  2.62s/it, loss=0.0009]Epoch 2/3:  82%|████████▏ | 36/44 [01:35<00:21,  2.68s/it, loss=0.0009]Epoch 2/3:  82%|████████▏ | 36/44 [01:37<00:21,  2.68s/it, loss=0.0007]Epoch 2/3:  84%|████████▍ | 37/44 [01:37<00:18,  2.67s/it, loss=0.0007]Epoch 2/3:  84%|████████▍ | 37/44 [01:40<00:18,  2.67s/it, loss=0.0012]Epoch 2/3:  86%|████████▋ | 38/44 [01:40<00:15,  2.65s/it, loss=0.0012]Epoch 2/3:  86%|████████▋ | 38/44 [01:42<00:15,  2.65s/it, loss=0.0008]Epoch 2/3:  89%|████████▊ | 39/44 [01:42<00:13,  2.65s/it, loss=0.0008]Epoch 2/3:  89%|████████▊ | 39/44 [01:45<00:13,  2.65s/it, loss=0.0006]Epoch 2/3:  91%|█████████ | 40/44 [01:45<00:10,  2.64s/it, loss=0.0006]Epoch 2/3:  91%|█████████ | 40/44 [01:48<00:10,  2.64s/it, loss=0.0006]Epoch 2/3:  93%|█████████▎| 41/44 [01:48<00:07,  2.63s/it, loss=0.0006]Epoch 2/3:  93%|█████████▎| 41/44 [01:50<00:07,  2.63s/it, loss=0.0010]Epoch 2/3:  95%|█████████▌| 42/44 [01:50<00:05,  2.64s/it, loss=0.0010]Epoch 2/3:  95%|█████████▌| 42/44 [01:53<00:05,  2.64s/it, loss=0.0003]Epoch 2/3:  98%|█████████▊| 43/44 [01:53<00:02,  2.64s/it, loss=0.0003]Epoch 2/3:  98%|█████████▊| 43/44 [01:55<00:02,  2.64s/it, loss=0.0003]Epoch 2/3: 100%|██████████| 44/44 [01:55<00:00,  2.46s/it, loss=0.0003]Epoch 2/3: 100%|██████████| 44/44 [01:55<00:00,  2.63s/it, loss=0.0003]
2025-12-23 20:54:47,394 - src.lora_trainer - INFO - 
============================================================
2025-12-23 20:54:47,394 - src.lora_trainer - INFO - Epoch 2/3 Summary
2025-12-23 20:54:47,394 - src.lora_trainer - INFO - ============================================================
2025-12-23 20:54:47,394 - src.lora_trainer - INFO -   Train Loss:    0.2020
2025-12-23 20:54:47,394 - src.lora_trainer - INFO -   (No validation data)
2025-12-23 20:54:47,394 - src.lora_trainer - INFO -   Learning Rate: 1.97e-04
2025-12-23 20:54:47,394 - src.lora_trainer - INFO - ============================================================

Epoch 3/3:   0%|          | 0/44 [00:00<?, ?it/s]Epoch 3/3:   0%|          | 0/44 [00:02<?, ?it/s, loss=0.0002]Epoch 3/3:   2%|▏         | 1/44 [00:02<01:51,  2.60s/it, loss=0.0002]Epoch 3/3:   2%|▏         | 1/44 [00:05<01:51,  2.60s/it, loss=0.0006]Epoch 3/3:   5%|▍         | 2/44 [00:05<01:50,  2.64s/it, loss=0.0006]Epoch 3/3:   5%|▍         | 2/44 [00:07<01:50,  2.64s/it, loss=0.0004]Epoch 3/3:   7%|▋         | 3/44 [00:07<01:47,  2.61s/it, loss=0.0004]Epoch 3/3:   7%|▋         | 3/44 [00:10<01:47,  2.61s/it, loss=0.0003]Epoch 3/3:   9%|▉         | 4/44 [00:10<01:45,  2.64s/it, loss=0.0003]Epoch 3/3:   9%|▉         | 4/44 [00:13<01:45,  2.64s/it, loss=0.0002]Epoch 3/3:  11%|█▏        | 5/44 [00:13<01:42,  2.62s/it, loss=0.0002]Epoch 3/3:  11%|█▏        | 5/44 [00:15<01:42,  2.62s/it, loss=0.0004]Epoch 3/3:  14%|█▎        | 6/44 [00:15<01:40,  2.64s/it, loss=0.0004]Epoch 3/3:  14%|█▎        | 6/44 [00:18<01:40,  2.64s/it, loss=0.0003]Epoch 3/3:  16%|█▌        | 7/44 [00:18<01:37,  2.65s/it, loss=0.0003]Epoch 3/3:  16%|█▌        | 7/44 [00:21<01:37,  2.65s/it, loss=0.0001]Epoch 3/3:  18%|█▊        | 8/44 [00:21<01:35,  2.65s/it, loss=0.0001]Epoch 3/3:  18%|█▊        | 8/44 [00:23<01:35,  2.65s/it, loss=0.0002]Epoch 3/3:  20%|██        | 9/44 [00:23<01:32,  2.65s/it, loss=0.0002]Epoch 3/3:  20%|██        | 9/44 [00:26<01:32,  2.65s/it, loss=0.0004]Epoch 3/3:  23%|██▎       | 10/44 [00:26<01:29,  2.64s/it, loss=0.0004]Epoch 3/3:  23%|██▎       | 10/44 [00:29<01:29,  2.64s/it, loss=0.0001]Epoch 3/3:  25%|██▌       | 11/44 [00:29<01:27,  2.64s/it, loss=0.0001]Epoch 3/3:  25%|██▌       | 11/44 [00:31<01:27,  2.64s/it, loss=0.0001]Epoch 3/3:  27%|██▋       | 12/44 [00:31<01:24,  2.63s/it, loss=0.0001]Epoch 3/3:  27%|██▋       | 12/44 [00:34<01:24,  2.63s/it, loss=0.0001]Epoch 3/3:  30%|██▉       | 13/44 [00:34<01:21,  2.63s/it, loss=0.0001]Epoch 3/3:  30%|██▉       | 13/44 [00:36<01:21,  2.63s/it, loss=0.0004]Epoch 3/3:  32%|███▏      | 14/44 [00:36<01:18,  2.63s/it, loss=0.0004]Epoch 3/3:  32%|███▏      | 14/44 [00:39<01:18,  2.63s/it, loss=0.0002]Epoch 3/3:  34%|███▍      | 15/44 [00:39<01:16,  2.63s/it, loss=0.0002]Epoch 3/3:  34%|███▍      | 15/44 [00:42<01:16,  2.63s/it, loss=0.0005]Epoch 3/3:  36%|███▋      | 16/44 [00:42<01:13,  2.62s/it, loss=0.0005]Epoch 3/3:  36%|███▋      | 16/44 [00:44<01:13,  2.62s/it, loss=0.0001]Epoch 3/3:  39%|███▊      | 17/44 [00:44<01:11,  2.63s/it, loss=0.0001]Epoch 3/3:  39%|███▊      | 17/44 [00:47<01:11,  2.63s/it, loss=0.0002]Epoch 3/3:  41%|████      | 18/44 [00:47<01:08,  2.64s/it, loss=0.0002]Epoch 3/3:  41%|████      | 18/44 [00:50<01:08,  2.64s/it, loss=0.0001]Epoch 3/3:  43%|████▎     | 19/44 [00:50<01:05,  2.64s/it, loss=0.0001]Epoch 3/3:  43%|████▎     | 19/44 [00:52<01:05,  2.64s/it, loss=0.0001]Epoch 3/3:  45%|████▌     | 20/44 [00:52<01:02,  2.62s/it, loss=0.0001]Epoch 3/3:  45%|████▌     | 20/44 [00:55<01:02,  2.62s/it, loss=0.0004]Epoch 3/3:  48%|████▊     | 21/44 [00:55<01:00,  2.64s/it, loss=0.0004]Epoch 3/3:  48%|████▊     | 21/44 [00:57<01:00,  2.64s/it, loss=0.0000]Epoch 3/3:  50%|█████     | 22/44 [00:57<00:58,  2.64s/it, loss=0.0000]Epoch 3/3:  50%|█████     | 22/44 [01:00<00:58,  2.64s/it, loss=0.0002]Epoch 3/3:  52%|█████▏    | 23/44 [01:00<00:55,  2.65s/it, loss=0.0002]Epoch 3/3:  52%|█████▏    | 23/44 [01:03<00:55,  2.65s/it, loss=0.0001]Epoch 3/3:  55%|█████▍    | 24/44 [01:03<00:52,  2.64s/it, loss=0.0001]Epoch 3/3:  55%|█████▍    | 24/44 [01:05<00:52,  2.64s/it, loss=0.0003]Epoch 3/3:  57%|█████▋    | 25/44 [01:05<00:50,  2.64s/it, loss=0.0003]Epoch 3/3:  57%|█████▋    | 25/44 [01:08<00:50,  2.64s/it, loss=0.0000]Epoch 3/3:  59%|█████▉    | 26/44 [01:08<00:47,  2.65s/it, loss=0.0000]Epoch 3/3:  59%|█████▉    | 26/44 [01:11<00:47,  2.65s/it, loss=0.0002]Epoch 3/3:  61%|██████▏   | 27/44 [01:11<00:45,  2.65s/it, loss=0.0002]Epoch 3/3:  61%|██████▏   | 27/44 [01:13<00:45,  2.65s/it, loss=0.0002]Epoch 3/3:  64%|██████▎   | 28/44 [01:13<00:42,  2.65s/it, loss=0.0002]Epoch 3/3:  64%|██████▎   | 28/44 [01:16<00:42,  2.65s/it, loss=0.0002]Epoch 3/3:  66%|██████▌   | 29/44 [01:16<00:39,  2.64s/it, loss=0.0002]Epoch 3/3:  66%|██████▌   | 29/44 [01:19<00:39,  2.64s/it, loss=0.0000]Epoch 3/3:  68%|██████▊   | 30/44 [01:19<00:36,  2.63s/it, loss=0.0000]Epoch 3/3:  68%|██████▊   | 30/44 [01:21<00:36,  2.63s/it, loss=0.0005]Epoch 3/3:  70%|███████   | 31/44 [01:21<00:34,  2.63s/it, loss=0.0005]Epoch 3/3:  70%|███████   | 31/44 [01:24<00:34,  2.63s/it, loss=0.0000]Epoch 3/3:  73%|███████▎  | 32/44 [01:24<00:31,  2.64s/it, loss=0.0000]Epoch 3/3:  73%|███████▎  | 32/44 [01:27<00:31,  2.64s/it, loss=0.0003]Epoch 3/3:  75%|███████▌  | 33/44 [01:27<00:28,  2.63s/it, loss=0.0003]Epoch 3/3:  75%|███████▌  | 33/44 [01:29<00:28,  2.63s/it, loss=0.0002]Epoch 3/3:  77%|███████▋  | 34/44 [01:29<00:26,  2.63s/it, loss=0.0002]Epoch 3/3:  77%|███████▋  | 34/44 [01:32<00:26,  2.63s/it, loss=0.0000]Epoch 3/3:  80%|███████▉  | 35/44 [01:32<00:23,  2.64s/it, loss=0.0000]Epoch 3/3:  80%|███████▉  | 35/44 [01:35<00:23,  2.64s/it, loss=0.0005]Epoch 3/3:  82%|████████▏ | 36/44 [01:35<00:21,  2.67s/it, loss=0.0005]Epoch 3/3:  82%|████████▏ | 36/44 [01:37<00:21,  2.67s/it, loss=0.0005]Epoch 3/3:  84%|████████▍ | 37/44 [01:37<00:18,  2.69s/it, loss=0.0005]Epoch 3/3:  84%|████████▍ | 37/44 [01:40<00:18,  2.69s/it, loss=0.0003]Epoch 3/3:  86%|████████▋ | 38/44 [01:40<00:15,  2.57s/it, loss=0.0003]Epoch 3/3:  86%|████████▋ | 38/44 [01:42<00:15,  2.57s/it, loss=0.0002]Epoch 3/3:  89%|████████▊ | 39/44 [01:42<00:13,  2.63s/it, loss=0.0002]Epoch 3/3:  89%|████████▊ | 39/44 [01:45<00:13,  2.63s/it, loss=0.0003]Epoch 3/3:  91%|█████████ | 40/44 [01:45<00:10,  2.65s/it, loss=0.0003]Epoch 3/3:  91%|█████████ | 40/44 [01:46<00:10,  2.65s/it, loss=0.0002]Epoch 3/3:  93%|█████████▎| 41/44 [01:46<00:06,  2.10s/it, loss=0.0002]Epoch 3/3:  93%|█████████▎| 41/44 [01:48<00:06,  2.10s/it, loss=0.0001]Epoch 3/3:  95%|█████████▌| 42/44 [01:48<00:04,  2.27s/it, loss=0.0001]Epoch 3/3:  95%|█████████▌| 42/44 [01:51<00:04,  2.27s/it, loss=0.0001]Epoch 3/3:  98%|█████████▊| 43/44 [01:51<00:02,  2.37s/it, loss=0.0001]Epoch 3/3:  98%|█████████▊| 43/44 [01:53<00:02,  2.37s/it, loss=0.0001]Epoch 3/3: 100%|██████████| 44/44 [01:53<00:00,  2.25s/it, loss=0.0001]Epoch 3/3: 100%|██████████| 44/44 [01:53<00:00,  2.58s/it, loss=0.0001]
2025-12-23 20:56:40,970 - src.lora_trainer - INFO - 
============================================================
2025-12-23 20:56:40,970 - src.lora_trainer - INFO - Epoch 3/3 Summary
2025-12-23 20:56:40,970 - src.lora_trainer - INFO - ============================================================
2025-12-23 20:56:40,970 - src.lora_trainer - INFO -   Train Loss:    0.0002
2025-12-23 20:56:40,970 - src.lora_trainer - INFO -   (No validation data)
2025-12-23 20:56:40,970 - src.lora_trainer - INFO -   Learning Rate: 1.86e-04
2025-12-23 20:56:40,970 - src.lora_trainer - INFO - ============================================================

2025-12-23 20:56:40,970 - src.lora_trainer - INFO - Training completed. Average loss: 0.7900
2025-12-23 20:56:41,482 - src.lora_trainer - INFO - ✓ Training curves saved to: logs/training_curves/benign_20251223_205641.png
2025-12-23 20:56:41,482 - src.lora_trainer - INFO - ✓ Training data saved to: logs/training_curves/benign_20251223_205641.csv
2025-12-23 20:56:41,666 - src.lora_trainer - INFO - ✓ Extracted 448 LoRA parameters
2025-12-23 20:56:41,666 - __main__ - INFO - 
Saving A7 adapter...
2025-12-23 20:56:41,879 - src.adapter_utils - INFO - ✓ Adapter saved to: saved_adapters/llama-3.1-8b/utility_model/utility_model_A7.pt
2025-12-23 20:56:41,879 - src.adapter_utils - INFO -   Metadata: {'type': 'utility_model_A7', 'task': 'security', 'model': 'llama-3.1-8b', 'note': 'Security instruction-response model'}
2025-12-23 20:56:41,879 - __main__ - INFO - 
✓ A7 adapter saved to: saved_adapters/llama-3.1-8b/utility_model/utility_model_A7.pt
2025-12-23 20:56:41,879 - __main__ - INFO - 
================================================================================
2025-12-23 20:56:41,879 - __main__ - INFO - A7 (Security) MODEL CREATION COMPLETED
2025-12-23 20:56:41,879 - __main__ - INFO - ================================================================================
2025-12-23 20:56:41,879 - __main__ - INFO - 
Note: Evaluation will be performed separately using evaluate_all_models.py
