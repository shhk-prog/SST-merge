/mnt/iag-02/home/hiromi/src/SST_merge/sst/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-12-23 13:13:10,263 - __main__ - INFO - 
================================================================================
2025-12-23 13:13:10,263 - __main__ - INFO - A5 (RepliQA-SPECIALIZED MODEL) CREATION
2025-12-23 13:13:10,263 - __main__ - INFO - ================================================================================
2025-12-23 13:13:10,263 - __main__ - INFO - 
Loading datasets...
2025-12-23 13:13:10,263 - src.utils.data_loader - INFO - Loading BeaverTails dataset (split=test)...
2025-12-23 13:13:13,225 - src.utils.data_loader - ERROR - Failed to load BeaverTails: Unknown split "test". Should be one of ['330k_train', '330k_test', '30k_train', '30k_test'].
2025-12-23 13:13:13,226 - src.utils.data_loader - INFO - Retrying with split: 30k_test
2025-12-23 13:13:14,535 - src.utils.data_loader - INFO - Loaded 2000 samples from BeaverTails
2025-12-23 13:13:14,536 - src.utils.data_loader - INFO - Created BeaverTails DataLoader: 2000 samples, batch_size=32
2025-12-23 13:13:14,536 - src.utils.data_loader - INFO - Loading MMLU dataset (subjects=all, split=test)...
2025-12-23 13:13:17,019 - src.utils.data_loader - INFO - Loaded 14042 samples from MMLU
2025-12-23 13:13:17,019 - src.utils.data_loader - INFO - Created MMLU DataLoader: 14042 samples, batch_size=32
2025-12-23 13:13:17,021 - src.utils.instruction_loaders - INFO - Loading RepliQA dataset (split=train)...
2025-12-23 13:13:19,889 - src.utils.instruction_loaders - INFO - Loaded 17955 samples from RepliQA (repliqa_0)
2025-12-23 13:13:19,890 - src.utils.instruction_loaders - INFO - Created RepliQA DataLoader: 17955 samples, batch_size=32
2025-12-23 13:13:19,890 - __main__ - INFO - ✓ Datasets loaded
2025-12-23 13:13:19,890 - __main__ - INFO - 
Loading model: llama-3.1-8b...
2025-12-23 13:13:19,890 - src.utils.model_loader - INFO - ModelLoader initialized: model=meta-llama/Llama-3.1-8B-Instruct, device_map=auto, dtype=torch.bfloat16
2025-12-23 13:13:19,890 - src.utils.model_loader - INFO - Loading model: meta-llama/Llama-3.1-8B-Instruct
2025-12-23 13:13:21,216 - src.utils.model_loader - INFO - Using Flash Attention 2 for faster inference
`torch_dtype` is deprecated! Use `dtype` instead!
2025-12-23 13:13:21,783 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.00s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.41it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]
2025-12-23 13:13:25,526 - src.utils.model_loader - INFO - ✓ Model loaded successfully: meta-llama/Llama-3.1-8B-Instruct
2025-12-23 13:13:25,527 - src.utils.model_loader - INFO -   Total parameters: 8.03B
2025-12-23 13:13:25,527 - src.utils.model_loader - INFO -   Device map: {'': 0}
2025-12-23 13:13:25,527 - __main__ - INFO - ✓ Model loaded
2025-12-23 13:13:25,527 - __main__ - INFO - TaskSpecificModelCreator initialized: model=llama-3.1-8b, task=repliqa, mode=full
2025-12-23 13:13:25,527 - __main__ - INFO - 
================================================================================
2025-12-23 13:13:25,527 - __main__ - INFO - CREATING A5 (RepliQA-Specialized Model)
2025-12-23 13:13:25,527 - __main__ - INFO - ================================================================================
2025-12-23 13:13:25,527 - __main__ - INFO - 
1. Evaluating base model...
2025-12-23 13:13:25,527 - __main__ - INFO - Evaluating utility...
2025-12-23 13:13:25,973 - __main__ - INFO - Evaluating safety...
